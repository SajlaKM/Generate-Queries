{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMPSo5e8IgV4mmrJVdaNHy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SajlaKM/Generate-Queries/blob/main/Generate_queries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Install important libraries"
      ],
      "metadata": {
        "id": "2RqNLk2lZ94V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wreHbLQgi8Xi",
        "outputId": "fb81f075-fd3f-45a2-dfc8-a64e4e98d6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fitz in /usr/local/lib/python3.11/dist-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (20240706)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.11/dist-packages (from fitz) (5.0.9)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.11/dist-packages (from fitz) (7.1.0)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.11/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from fitz) (5.3.2)\n",
            "Requirement already satisfied: nipype in /usr/local/lib/python3.11/dist-packages (from fitz) (1.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fitz) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fitz) (2.2.2)\n",
            "Requirement already satisfied: pyxnat in /usr/local/lib/python3.11/dist-packages (from fitz) (1.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fitz) (1.13.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.11/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.11/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2025.1.31)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2->fitz) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->fitz) (6.5.2)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (2.0.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (6.3.2)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (3.20.1)\n",
            "Requirement already satisfied: traits>=6.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (7.0.2)\n",
            "Requirement already satisfied: acres in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: etelemetry>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion!=1.2 in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: puremagic in /usr/local/lib/python3.11/dist-packages (from nipype->fitz) (1.28)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fitz) (2025.1)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.11/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.11/dist-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install fitz nltk sumy transformers pdfminer.six torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tools\n",
        "!pip install pymupdf\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "HnMdq1hDJJ0_",
        "outputId": "e40de710-164a-4b89-acb9-01a6cd5e3375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tools in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: pytils in /usr/local/lib/python3.11/dist-packages (from tools) (0.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tools) (1.17.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from tools) (5.3.1)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Extract  PDF file"
      ],
      "metadata": {
        "id": "wHQnn4QlaF6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymupdf\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to Extract Text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = pymupdf.open(pdf_path)\n",
        "    text = \"\"\n",
        "\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\") + \"\\n\"\n",
        "\n",
        "    return text\n",
        "\n",
        "# Load PDF file to be summarized\n",
        "pdf_text = extract_text_from_pdf(\"Artificial Intelligence.pdf\")\n",
        "print(pdf_text[:1000])\n",
        "\n",
        "# Preprocess Text\n",
        "pdf_text = re.sub(r'\\s+', ' ', pdf_text).strip()  # Remove extra spaces\n",
        "\n",
        "doc = nlp(pdf_text)\n",
        "sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "print(f\"\\nExtracted {len(sentences)} sentences from the PDF!\")"
      ],
      "metadata": {
        "id": "Lb_EgNYAjo7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e05cb2-af80-4af8-d097-7a9eb0826faa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/307981242\n",
            "Essay: Artiﬁcial Intelligence: Boon or Bane?\n",
            "Article  in  SSRN Electronic Journal · August 2016\n",
            "DOI: 10.2139/ssrn.2836438\n",
            "CITATIONS\n",
            "25\n",
            "READS\n",
            "225,383\n",
            "1 author:\n",
            "Amit Tyagi\n",
            "Microsoft\n",
            "3 PUBLICATIONS   25 CITATIONS   \n",
            "SEE PROFILE\n",
            "All content following this page was uploaded by Amit Tyagi on 06 October 2017.\n",
            "The user has requested enhancement of the downloaded file.\n",
            "\n",
            "   Artificial Intelligence: Boon or Bane? \n",
            " \n",
            "Amit Tyagi (Leibniz Universität Hannover) \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "                Source: Elektor Magazine \n",
            "ABSTRACT \n",
            " \n",
            "Artificial Intelligence (AI) is transforming the nature of almost everything which is connected \n",
            "to human life e.g. employment, economy, communication, warfare, privacy, security, ethics, \n",
            "healthcare etc. However, we are yet to see its evolution in long-term, whether it’s leading \n",
            "humanity towards making this planet a better place to live or a place which is f\n",
            "\n",
            "Extracted 340 sentences from the PDF!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Extractive Summary"
      ],
      "metadata": {
        "id": "d24LK3kyaURn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function for Extractive Summarization using spaCy\n",
        "def summarize_text_spacy(text, num_sentences=5):\n",
        "    # Tokenize sentences using spaCy\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "    # Extract the first few sentences\n",
        "    summary = \" \".join(sentences[:num_sentences])\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Generate Extractive Summary\n",
        "extractive_summary = summarize_text_spacy(pdf_text, num_sentences=10)\n",
        "\n",
        "print(\" Extractive Summary:\\n\", extractive_summary)\n"
      ],
      "metadata": {
        "id": "Kmtq4kUrRX6m",
        "outputId": "a8d523ba-ba6c-48c5-ac19-f780dcc86a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Extractive Summary:\n",
            " See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/307981242 Essay: Artiﬁcial Intelligence: Boon or Bane? Article in SSRN Electronic Journal · August 2016 DOI: 10.2139/ssrn.2836438 CITATIONS 25 READS 225,383 1 author: Amit Tyagi Microsoft 3 PUBLICATIONS 25 CITATIONS SEE PROFILE All content following this page was uploaded by Amit Tyagi on 06 October 2017. The user has requested enhancement of the downloaded file. Artificial Intelligence: Boon or Bane? Amit Tyagi (Leibniz Universität Hannover) Source: Elektor Magazine ABSTRACT Artificial Intelligence (AI) is transforming the nature of almost everything which is connected to human life e.g. employment, economy, communication, warfare, privacy, security, ethics, healthcare etc. However, we are yet to see its evolution in long-term, whether it’s leading humanity towards making this planet a better place to live or a place which is full of disaster. Every technology has its advantages and disadvantages but advantages always outweigh disadvantages for the technology to survive in the market. Nonetheless, for Artificial Intelligence we are not yet sure whether in the long-term positive effects will always keep outweighing the negative effects and if that is not the case then we are in serious trouble. If we look around us, on the one hand, we seem to embrace the change being brought by technology, be it smart home, smart healthcare, Industry 4.0 or autonomous cars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Abstractive Summary"
      ],
      "metadata": {
        "id": "n5MA4h8waYk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load Pre-trained Summarization Pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
        "\n",
        "# Function for Abstractive Summarization\n",
        "def summarize_text_abstractive(text, max_length=150, min_length=50):\n",
        "    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "# Generate Abstractive Summary\n",
        "abstractive_summary = summarize_text_abstractive(pdf_text, max_length=150, min_length=50)\n",
        "\n",
        "print(\"Abstractive Summary:\\n\", abstractive_summary)\n"
      ],
      "metadata": {
        "id": "4n5H6bh0R6yl",
        "outputId": "64143ee7-a38c-490b-e128-05ddd054c1f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8667 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstractive Summary:\n",
            " if we keep ignoring the social bugs of AI, it could be a serious threat to humanity . it is important to have a centralized global governing body which can make sure that we can mitigate the consequences . if you are embracing AI, you will be able to create a system that can be used to solve problems .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Summary of Each page"
      ],
      "metadata": {
        "id": "GINwFZ8OadPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymupdf\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load Pre-trained Summarization Model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Function to Extract Text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = pymupdf.open(pdf_path)  # Open PDF\n",
        "    pages_text = []\n",
        "\n",
        "    for i in range(len(doc)):  # Iterate through pages\n",
        "        text = doc[i].get_text(\"text\")\n",
        "        if text.strip():  # Ignore empty pages\n",
        "            pages_text.append(text)\n",
        "\n",
        "    return pages_text\n",
        "\n",
        "# Function to Split Long Text into Chunks\n",
        "def split_text(text, max_words=400):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
        "\n",
        "# Function to Summarize Each Page\n",
        "def summarize_pdf(pdf_path, start_page=2):  # Skip cover & contents (Page 0 & 1)\n",
        "    pages_text = extract_text_from_pdf(pdf_path)\n",
        "    summaries = {}\n",
        "\n",
        "    for i in range(start_page, len(pages_text)):  # Start from actual content\n",
        "        page_text = pages_text[i]\n",
        "\n",
        "        if len(page_text.split()) > 50:  # Avoid summarizing very short pages\n",
        "            text_chunks = split_text(page_text, max_words=400)  # Break large text\n",
        "            summary_chunks = [summarizer(chunk, max_length=150, min_length=50, do_sample=False)[0]['summary_text'] for chunk in text_chunks]\n",
        "            summary = \" \".join(summary_chunks)  # Combine summaries\n",
        "            summaries[f\"Page {i+1}\"] = summary  # Store summary\n",
        "\n",
        "    return summaries\n",
        "\n",
        "# Run the summarization on your PDF\n",
        "pdf_path = \"/content/Artificial Intelligence.pdf\"  # Replace with your file path\n",
        "page_wise_summaries = summarize_pdf(pdf_path, start_page=2)\n",
        "\n",
        "# Print Summaries\n",
        "for page, summary in page_wise_summaries.items():\n",
        "    print(f\"\\n# {page} Summary:\\n{summary}\")\n"
      ],
      "metadata": {
        "id": "KIEUQO0VpU9S",
        "outputId": "f9c49236-64f0-4627-a134-a4e4c8623f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "Your max_length is set to 150, but your input_length is only 58. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=29)\n",
            "Your max_length is set to 150, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
            "Your max_length is set to 150, but your input_length is only 98. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# Page 3 Summary:\n",
            "Current state of AI: ........................................................................................................................ 6 2.1 Techniques (Deep Learning) & Companies (IBM, Google, Facebook, Microsoft, OpenAI): 7 2.2 Next steps of AIs: ............................................................ 10 2.3 Problem related to AI:  ........................................................................................................................................... 102.3. Between AIs & Humans:  ............................................................................................. 11 2.4 Policies & Laws:  ..................................................................................................................... 13 2.5 Possible Solutions:   ................................................. 14 3. CONCLUSION: 14 4. BIBLIOGRAPHY: 15.\n",
            "\n",
            "# Page 4 Summary:\n",
            "Artificial Intelligence is intelligence exhibited by machines. Eric Schmidt, the executive chairman of Alphabet, the parent company of Google, says that AI could be leveraged in order to solve major challenges, including climate change, disease diagnosis, drug discovery, microeconomics, theorem proving and protein folding. The progress in AI is also bringing steady consequences e.g. eradicating jobs by the means of work automation. Industry 4.0 creates what has been called a ‘smart factory’ wherein large number of robots take forward the whole manufacturing process. If in the near future, machines achieve superhuman intelligence, then many ethical questions arise.\n",
            "\n",
            "# Page 5 Summary:\n",
            "There are many issues which are related to the emergence of Artificial Intelligence. In this essay, I will focus on those I consider significant enough to be discussed. A very important issue nowadays is unemployment. Another important issue is related to morality. Nick Bostrom said that \"machine intelligence is the last invention that humanity will ever need to make\" The development of AI is debatable in my opinion. If we are going to continue developing AI, then we have to make sure to eradicate all the issue we have now in our mind. All these issues can be tackled if we make a global framework of rule and regulations.\n",
            "\n",
            "# Page 6 Summary:\n",
            "In the recent years, there have been several advancements in the development of AI. In cognitive science, intelligence is defined in many ways which include one’s capacity for reasoning, logic, understanding, planning, problem solving, self-awareness, and emotional knowledge. A Human-level intelligent machine should have an ability to pass several tests; one of such tests is the Turing test.\n",
            "\n",
            "# Page 7 Summary:\n",
            "The pace of evolution of artificial intelligence is speeding up. There is no perfect test which can prove a machine perfectly human-level intelligent. Google, Facebook, Microsoft and IBM have dived into AI research. The term ‘Robot’ was first coined by Karel Čapek in his play R.U.R (Rossum’s Universal Robots) in 1921.\n",
            "\n",
            "# Page 8 Summary:\n",
            "Since Google’s acquisition of DeepMind, they are working intensively on making its AI better at playing old Atari games. After putting a lot of effort to develop narrow AI based intelligence, now tech-industry giants are going towards Strong AI. Unlike Narrow AI, Strong AI is focused on a problem domain which can consist of any problem in the real world.\n",
            "\n",
            "# Page 9 Summary:\n",
            "IBM indicated AI as one of its highest potential growth areas. Companies like Google have even started utilizing Deep Learning in their current running projects to improve their services. IBM made some of the features of Watson available to the developers via its Cloud API (Application Programming Interface)\n",
            "\n",
            "# Page 10 Summary:\n",
            "The automobile industry is investing a vast amount of money to embed AI into cars. Tesla Motors has already introduced AI into their cars which enable auto-pilot mode and other lane changing features. Google has recently launched an open-source version of its Artificial Intelligence engine named TensorFlow.\n",
            "\n",
            "# Page 11 Summary:\n",
            "The next steps in AI mostly include generalizing the intelligence and creating as many use cases as possible. OpenAI wants to further advance AI in a way that benefits society as a whole and is freed from the need of generating revenues. There is a huge potential in this technology for the usage at various commercial levels. Artificial Intelligence has impressive capabilities today but they are narrow in nature. Researchers are fighting to widen up those capabilities to make it as general as possible. different domains all using AI technology while developing it further in parallel to achieve their desired results.\n",
            "\n",
            "# Page 12 Summary:\n",
            "In the near term, automation of services is also going to impact on employment and AI is going to play a major role in making that possible. Once AI reaches human-level intelligence, further development of self-optimizing AIs is unpredictable. Moral implications are formed by machine learning does not necessary include human teachers anymore. The question arising here is what happens when our computers get better than we are in different areas of life. An AI-friend will only focus on its owner’s needs, whereas a human relationship flourishes through the exchange of favours. Another interesting scenario has been portrayed in the very recent movie called Ex-Machina.\n",
            "\n",
            "# Page 13 Summary:\n",
            "A recent bid for the acquisition of a German robotic company Kuka by a Chinese company called Midea Group was $ 5 billion. Kuka is one of the world’s largest robotic companies. China is famous for low-paid migrant labour and Chinese enterprises want to automate the manufacturing process. If not consciously planned, power structures will impact the political and social freedom both locally and globally.\n",
            "\n",
            "# Page 14 Summary:\n",
            "Baidu’s research indicates as how the digital footprints can be used to determine the city dynamics. Baidu is mining its data for the city planners to suggest them the right spot to put transportation, shop, and other facilities etc. The European Parliament committee has set up a working group on legal questions related to the development of Artificial Intelligence. This group will be responsible for drafting civil law rules in connection with research in Artificial Intelligence and Robotics. The same applies to current bank algorithms using machine learning to evaluate creditability.\n",
            "\n",
            "# Page 15 Summary:\n",
            "It is really difficult to predict when we can reach singularity despite the fact that there are several predictions by some AI experts. If we reach that point in the future, then it is really important to have a centralized global governing body which lays down the framework for prioritizing the positive outcome over its own interest. Technology is different than any other technology which humanity has ever developed. It is the change which not only starts exhibiting soon its positive impact on society but severely negative impacts, too. If we are embracing it as a change which is expected to change the way we live, then we should be happily ready to face the consequences.\n",
            "\n",
            "# Page 16 Summary:\n",
            "I conclude that if we keep ignoring social bugs of AI, it could be a serious threat to humanity. However, whatever the case will eventually be, we certainly need a legal policy framework which can make sure to mitigate the challenges associated with AI.\n",
            "\n",
            "# Page 17 Summary:\n",
            "YouTube. (2016). DARC: How Category Confusion Affects Drone Law And Policy. At 11:30 min [online] Available at: https://www.youtube.com/watch?v=dODu9AyDG9Q [Accessed 15 Aug. 2016]. YouTube. ( 2016). Be afraid, be very afraid: the robots are coming and they will destroy our livelihoods.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Split text into sentences"
      ],
      "metadata": {
        "id": "242DisnjczJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    \"\"\"Splits text into meaningful sentences using spaCy\"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [sent.text.strip() for sent in doc.sents]\n",
        "\n",
        "# Get sentences\n",
        "sentences = split_into_sentences(pdf_text)\n",
        "print(sentences[:5])  # Print first 5 sentences\n"
      ],
      "metadata": {
        "id": "Tw4NLnRTahvM",
        "outputId": "d05d3a7a-0ca2-47b9-8822-b534fccd689d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/307981242 Essay:', 'Artiﬁcial Intelligence: Boon or Bane?', 'Article in SSRN Electronic Journal · August 2016 DOI: 10.2139/ssrn.2836438 CITATIONS 25 READS 225,383 1 author: Amit Tyagi Microsoft 3 PUBLICATIONS 25 CITATIONS SEE PROFILE All content following this page was uploaded by Amit Tyagi on 06 October 2017.', 'The user has requested enhancement of the downloaded file.', 'Artificial Intelligence: Boon or Bane?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Extract important sentences to generate questions"
      ],
      "metadata": {
        "id": "WAGnynjRc968"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def extract_key_sentences(sentences, top_n=5):\n",
        "    \"\"\"Extracts key sentences using TF-IDF\"\"\"\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    X = vectorizer.fit_transform(sentences)\n",
        "\n",
        "    # Rank sentences by importance (sum of TF-IDF scores)\n",
        "    scores = X.sum(axis=1).A1\n",
        "    ranked_sentences = [sentences[i] for i in scores.argsort()[-top_n:][::-1]]\n",
        "\n",
        "    return ranked_sentences\n",
        "\n",
        "# Extract important sentences\n",
        "key_sentences = extract_key_sentences(sentences, top_n=10)\n",
        "print(key_sentences)\n"
      ],
      "metadata": {
        "id": "juKbLrLqcDox",
        "outputId": "01c8139c-7aef-47f2-eb4a-e0bc4d74f318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Despite the fact that we are counting on Artificial Intelligence as the next tool to revolutionize the way we live, work and interact with each other -- which will be mostly enabled by machine-learning techniques – it remains unclear as to how these intelligent agents will help to solve more complex problems than the ones existing today (e.g. Poverty, Epidemics, climate changes) while keeping in mind that the state of the art in AI today is to intelligently recognize images and smartly playing games.', 'There is a question to whether individual learning machines will exchange in a cloud-like manner their knowledge and thus should be collectively law suited or individually [20].While this might be an issue to deal with in the remote future, coping mechanisms to handle job displacements and unequal capital access caused by the widening imbalance of labour and capital [16] are going to be needed way earlier.', 'There was a very good scenario presented in the science-fiction movie called iRobot when a robot saves a police detective from a car crash while leaving a girl to die as according to machine intelligence her survival was statistically less likely than that of the police detective: Another more severe issue is related to the technological singularity which can be seen as the point in time when machines will achieve Human-Level Machine Intelligence (HLMI).', 'In order to create human-level machines intelligence, it is important to achieve advancements in Strong AI because well-structured problems e.g. chess, are solvable by AI, while ill-structured problems e.g. real world, are still relatively difficult for AI like the Winograd Schema Challenge (an alternative to the Turing test based on contextual language understanding and common-sense knowledge etc.)', '2.3.2 Between AI & Humans: Moral Issues: As soon as AI is able to compete with humans, it will not only lead to a fight for jobs on an economical level but maybe even intrude human relationships in the way that an AI-friend will only focus on its owner’s needs, whereas a human relationship flourishes through the exchange of favours (e.g. portrayed in the movie “Her”).', 'Eric Schmidt, the executive chairman of Alphabet, the parent company of Google, says that AI could be leveraged in order to solve major challenges, including climate change, disease diagnosis, drug discovery, microeconomics, theorem proving and protein folding.', 'Demis Hassabis, CEO of Deepmind -- an AI company recently acquired by Google and now AI division of Google -- said that the aim of DeepMind project is to leverage the power of AI as by solving intelligence in a general enough way, we can apply it to all sorts of things to make the world a better place to live [3].', 'Below is the bar chart which shows the growth in accuracy of their AI: Fig. 2: Accuracy in Google’s AI at playing old Atari games (Clark, 2015) 2.1.1 Techniques (Deep Learning) & Companies (IBM, Google, Facebook, Microsoft, OpenAI): Deep Learning is one of the most growing research areas in the domain of Artificial Intelligence.', 'One such system which is recently established by Tesla CEO Elon Musk is known as OpenAI. - Economical and Governmental agents: Understanding the process of AI development while it is still adjustable, becoming aware of issues arising and actively taking part in designing the future with policies and informed future planning.', 'Article in SSRN Electronic Journal · August 2016 DOI: 10.2139/ssrn.2836438 CITATIONS 25 READS 225,383 1 author: Amit Tyagi Microsoft 3 PUBLICATIONS 25 CITATIONS SEE PROFILE All content following this page was uploaded by Amit Tyagi on 06 October 2017.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Convert sentences to Questions"
      ],
      "metadata": {
        "id": "h9HMQ-_odF1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the question-generation model\n",
        "question_generator = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
        "\n",
        "def generate_questions(sentences):\n",
        "    \"\"\"Generate questions from important sentences\"\"\"\n",
        "    questions = []\n",
        "    for sentence in sentences:\n",
        "        q = question_generator(f\"generate question: {sentence}\", max_length=50)\n",
        "        questions.append(q[0]['generated_text'])\n",
        "    return questions\n",
        "\n",
        "# Generate questions\n",
        "generated_questions = generate_questions(key_sentences)\n",
        "\n",
        "# Display results\n",
        "for i, (q, a) in enumerate(zip(generated_questions, key_sentences)):\n",
        "    print(f\"Q{i+1}: {q}\")\n",
        "    print(f\"A{i+1}: {a}\\n\")\n"
      ],
      "metadata": {
        "id": "pAE-nZQ_cI45",
        "outputId": "ddb621b6-d9ea-4864-a5db-56b61b30a719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: AI\n",
            "A1: Despite the fact that we are counting on Artificial Intelligence as the next tool to revolutionize the way we live, work and interact with each other -- which will be mostly enabled by machine-learning techniques – it remains unclear as to how these intelligent agents will help to solve more complex problems than the ones existing today (e.g. Poverty, Epidemics, climate changes) while keeping in mind that the state of the art in AI today is to intelligently recognize images and smartly playing games.\n",
            "\n",
            "Q2: question\n",
            "A2: There is a question to whether individual learning machines will exchange in a cloud-like manner their knowledge and thus should be collectively law suited or individually [20].While this might be an issue to deal with in the remote future, coping mechanisms to handle job displacements and unequal capital access caused by the widening imbalance of labour and capital [16] are going to be needed way earlier.\n",
            "\n",
            "Q3: iRobot\n",
            "A3: There was a very good scenario presented in the science-fiction movie called iRobot when a robot saves a police detective from a car crash while leaving a girl to die as according to machine intelligence her survival was statistically less likely than that of the police detective: Another more severe issue is related to the technological singularity which can be seen as the point in time when machines will achieve Human-Level Machine Intelligence (HLMI).\n",
            "\n",
            "Q4: Strong AI\n",
            "A4: In order to create human-level machines intelligence, it is important to achieve advancements in Strong AI because well-structured problems e.g. chess, are solvable by AI, while ill-structured problems e.g. real world, are still relatively difficult for AI like the Winograd Schema Challenge (an alternative to the Turing test based on contextual language understanding and common-sense knowledge etc.)\n",
            "\n",
            "Q5: a human relationship flourishes through the exchange of favours (e.g. portrayed in the movie “Her”).\n",
            "A5: 2.3.2 Between AI & Humans: Moral Issues: As soon as AI is able to compete with humans, it will not only lead to a fight for jobs on an economical level but maybe even intrude human relationships in the way that an AI-friend will only focus on its owner’s needs, whereas a human relationship flourishes through the exchange of favours (e.g. portrayed in the movie “Her”).\n",
            "\n",
            "Q6: AI\n",
            "A6: Eric Schmidt, the executive chairman of Alphabet, the parent company of Google, says that AI could be leveraged in order to solve major challenges, including climate change, disease diagnosis, drug discovery, microeconomics, theorem proving and protein folding.\n",
            "\n",
            "Q7: True\n",
            "A7: Demis Hassabis, CEO of Deepmind -- an AI company recently acquired by Google and now AI division of Google -- said that the aim of DeepMind project is to leverage the power of AI as by solving intelligence in a general enough way, we can apply it to all sorts of things to make the world a better place to live [3].\n",
            "\n",
            "Q8: 2.1.1 Techniques (Deep Learning) & Companies (IBM, Google, Facebook, Microsoft, OpenAI)\n",
            "A8: Below is the bar chart which shows the growth in accuracy of their AI: Fig. 2: Accuracy in Google’s AI at playing old Atari games (Clark, 2015) 2.1.1 Techniques (Deep Learning) & Companies (IBM, Google, Facebook, Microsoft, OpenAI): Deep Learning is one of the most growing research areas in the domain of Artificial Intelligence.\n",
            "\n",
            "Q9: OpenAI\n",
            "A9: One such system which is recently established by Tesla CEO Elon Musk is known as OpenAI. - Economical and Governmental agents: Understanding the process of AI development while it is still adjustable, becoming aware of issues arising and actively taking part in designing the future with policies and informed future planning.\n",
            "\n",
            "Q10: not_duplicate\n",
            "A10: Article in SSRN Electronic Journal · August 2016 DOI: 10.2139/ssrn.2836438 CITATIONS 25 READS 225,383 1 author: Amit Tyagi Microsoft 3 PUBLICATIONS 25 CITATIONS SEE PROFILE All content following this page was uploaded by Amit Tyagi on 06 October 2017.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Save Queries and Answers into a json file"
      ],
      "metadata": {
        "id": "CJT4cryqdQC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Create a dictionary of Q&A\n",
        "qa_data = [{\"question\": q, \"answer\": a} for q, a in zip(generated_questions, key_sentences)]\n",
        "\n",
        "# Save to JSON file\n",
        "with open(\"qa_pairs.json\", \"w\") as f:\n",
        "    json.dump(qa_data, f, indent=4)\n",
        "\n",
        "print(\"Q&A pairs saved to qa_pairs.json\")\n"
      ],
      "metadata": {
        "id": "S-qVdLHycZm_",
        "outputId": "43534168-2778-4819-a4bc-7a07f089bc09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q&A pairs saved to qa_pairs.json\n"
          ]
        }
      ]
    }
  ]
}